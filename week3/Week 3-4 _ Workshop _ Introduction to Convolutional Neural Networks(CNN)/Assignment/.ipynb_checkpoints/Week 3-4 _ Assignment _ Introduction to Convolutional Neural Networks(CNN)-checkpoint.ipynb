{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "BHy57d3rLp7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "image_dir = Path(\"/content/drive/MyDrive/Brain_Tumor_Dataset\")\n",
        "train_dir = image_dir/'Training'\n",
        "test_dir = image_dir/'Testing'\n",
        "\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "XFOX7eh9Lu2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 124x124\n",
        "    transforms.Resize(size=(124, 124)),\n",
        "    # convert images to grayscale\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor() # Turn the image into a torch.Tensor and converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])\n",
        "# data_transfrom(img)"
      ],
      "metadata": {
        "id": "sq81NmiuLv9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
        "                                  transform=data_transform, # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "id": "SMmFDbhbL1KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as a list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "5gaYZZc_L4np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(dataset= ,# _______ fill in the dataset,\n",
        "                              batch_size=, # ___ specify the batch size to use (how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=True) # shuffle the data?\n",
        "\n",
        "test_loader = DataLoader(dataset=test_data,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_loader, test_loader"
      ],
      "metadata": {
        "id": "HtyKeTZBL7qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exe 1.1"
      ],
      "metadata": {
        "id": "W6ePkxj4Jxg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Implement a convolutional autoencoder model using PyTorch, where the encoder part consists of a convolutional layer, and the decoder part consists of a transpose convolutional layer.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Define the Model class that inherits from nn.Module and implements the convolutional and transpose convolutional layers.\n",
        "2. In the forward method of the Model class, apply the convolutional layer to the input images, followed by the transpose convolutional layer.\n",
        "3. Create an instance of the Model class and apply it to a batch of images from the train_loader dataset.\n",
        "4. Plot the original, convolved, and de-convolved images.\n",
        "5. Print the shapes of the input images, convolved images, and de-convolved images.\n"
      ],
      "metadata": {
        "id": "mhdEW-oULVyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xou6m6jpHQtp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exe 1.2\n",
        "##### Implement a Convolutional Autoencoder Model using PyTorch\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "1. Define the `Model` class that inherits from `nn.Module` and implements the convolutional and transpose convolutional layers.\n",
        "2. In the `forward` method of the `Model` class, apply the convolutional layer to the input images, followed by the transpose convolutional layer.\n",
        "3. Create an instance of the `Model` class and apply it to a batch of images from the `train_loader` dataset.\n",
        "4. Plot the original, convolved, and de-convolved images using the provided code snippet.\n",
        "5. Print the shapes of the input images, convolved images, and de-convolved images.\n"
      ],
      "metadata": {
        "id": "cdtRBPONJ10F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCzVBkLFJ4YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exe 1.3"
      ],
      "metadata": {
        "id": "JYJmikC8J5CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Implement a Convolutional Neural Network (CNN) Model with Custom Blur Kernel\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "1. Define the custom 3x3 blur kernel/filter using the provided code snippet, with the missing values to be filled in by the student.\n",
        "2. Apply the convolution filter to the input images using PyTorch's `torch.nn.functional.conv2d()` function, with the missing arguments to be filled in by the student.\n",
        "3. Plot the original and convolved images.\n"
      ],
      "metadata": {
        "id": "yJIlpA6MNc9x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBtLwDRVJ6EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exe 1.4"
      ],
      "metadata": {
        "id": "pgiR55AyJ6n5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Extend TinyVGG Model with Additional Layers and Evaluate Performance\n",
        "\n",
        "## Instructions:\n",
        "\n",
        "1. Modify the `TinyVGG` class by adding at least 2 more convolutional, ReLU, and max pooling layers using PyTorch's `nn.Sequential` module.\n",
        "2. Train and evaluate the modified `TinyVGG` model on a dataset of your choice.\n",
        "3. Compare the performance (e.g., accuracy, loss) of the original `TinyVGG` model and the modified `TinyVGG` model on the chosen dataset.\n"
      ],
      "metadata": {
        "id": "1yyFPmYLOk_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9HJUqLm0J7jS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}